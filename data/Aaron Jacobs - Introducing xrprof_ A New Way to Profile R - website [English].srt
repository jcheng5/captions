1
00:00:06,230 --> 00:00:06,830
Hi.

2
00:00:06,830 --> 00:00:08,300
My name is Aaron Jacobs.

3
00:00:08,300 --> 00:00:10,770
I work at Crescendo
Technology in Toronto,

4
00:00:10,770 --> 00:00:13,070
which is a company
focused on the technology

5
00:00:13,070 --> 00:00:14,690
side of sports betting.

6
00:00:14,690 --> 00:00:18,320
I'm also the author of xrprof,
which is a new profiling

7
00:00:18,320 --> 00:00:22,100
tool for R ecosystem that I'm
hoping to tell you about today.

8
00:00:22,100 --> 00:00:25,010
It's an honor and a privilege
to be part of this year's

9
00:00:25,010 --> 00:00:27,930
unusual RStudio conference.

10
00:00:27,930 --> 00:00:29,630
Now, from my
perspective, there's

11
00:00:29,630 --> 00:00:31,610
been an important change
in the R ecosystem

12
00:00:31,610 --> 00:00:34,910
in the last five or so years.

13
00:00:34,910 --> 00:00:38,300
R has traditionally been a
language for data analysis,

14
00:00:38,300 --> 00:00:42,950
visualization, summary,
exploration, locally,

15
00:00:42,950 --> 00:00:45,800
interactively with
some reporting.

16
00:00:45,800 --> 00:00:47,840
But with the emergence
of frameworks

17
00:00:47,840 --> 00:00:50,690
like Shiny and Plumber, it's
now being used more and more

18
00:00:50,690 --> 00:00:52,700
to build real applications.

19
00:00:52,700 --> 00:00:55,640
Now on the one hand, this has
created huge opportunities

20
00:00:55,640 --> 00:00:58,392
for R users to expand the
scope of what they can do,

21
00:00:58,392 --> 00:01:00,350
and the value that they
can bring to themselves

22
00:01:00,350 --> 00:01:01,820
in their organizations.

23
00:01:01,820 --> 00:01:03,860
But with this
increased opportunity

24
00:01:03,860 --> 00:01:06,410
has come much
increased complexity

25
00:01:06,410 --> 00:01:08,390
and increased responsibility.

26
00:01:08,390 --> 00:01:12,390
The reality is that
for many R users,

27
00:01:12,390 --> 00:01:13,980
presenting these
applications means

28
00:01:13,980 --> 00:01:17,160
that these applications have
users other than their authors

29
00:01:17,160 --> 00:01:18,330
for the first time.

30
00:01:18,330 --> 00:01:20,250
And often, they're
running in environments

31
00:01:20,250 --> 00:01:22,710
that are not the same local
development environments

32
00:01:22,710 --> 00:01:25,710
that we're used to.

33
00:01:25,710 --> 00:01:28,740
This means that you now
get bug reports like, hey,

34
00:01:28,740 --> 00:01:30,660
why is your Shiny app slow?

35
00:01:30,660 --> 00:01:33,690
Or this report is
taking an hour to run,

36
00:01:33,690 --> 00:01:35,280
but it used to take two minutes.

37
00:01:35,280 --> 00:01:36,930
What's happening?

38
00:01:36,930 --> 00:01:40,020
Now traditionally, to answer
performance related questions

39
00:01:40,020 --> 00:01:43,140
like this, you would make
use of a profiling tool.

40
00:01:43,140 --> 00:01:45,570
Profiling itself is a term
from computer science.

41
00:01:45,570 --> 00:01:48,420
It effectively means
that we collect data

42
00:01:48,420 --> 00:01:50,670
about where our program
is spending its time,

43
00:01:50,670 --> 00:01:55,560
effectively which functions
are being called most often.

44
00:01:55,560 --> 00:01:57,330
Now for R users,
this is actually

45
00:01:57,330 --> 00:02:00,270
kind of a comfortable
situation, because profiling

46
00:02:00,270 --> 00:02:01,410
produces data.

47
00:02:01,410 --> 00:02:04,150
And R users know how
to deal with data.

48
00:02:04,150 --> 00:02:07,770
We can use all of our
favorite tools for analysis,

49
00:02:07,770 --> 00:02:10,440
visualization, summary
of profiling data

50
00:02:10,440 --> 00:02:12,390
just like we could
with any other kind.

51
00:02:12,390 --> 00:02:15,240
And profiling itself is
a fundamentally empirical

52
00:02:15,240 --> 00:02:17,280
approach to
performance analysis.

53
00:02:17,280 --> 00:02:20,490
Don't guess, measure, and
then use those measurements

54
00:02:20,490 --> 00:02:22,860
to make informed decisions.

55
00:02:22,860 --> 00:02:26,070
Profiling is such an important
field for performance analysis

56
00:02:26,070 --> 00:02:30,360
that actually R has its own
built-in sampling profile.

57
00:02:30,360 --> 00:02:32,890
It's available for
the Rprof function,

58
00:02:32,890 --> 00:02:34,980
and there's a variety
of functions in base R

59
00:02:34,980 --> 00:02:36,840
and the wider
ecosystem that allow

60
00:02:36,840 --> 00:02:39,480
you to make use
of Rprof's format

61
00:02:39,480 --> 00:02:42,780
to produce again these
analyzes, these summaries,

62
00:02:42,780 --> 00:02:44,340
these visualizations.

63
00:02:44,340 --> 00:02:47,190
And so the proftools package
or the profvis package, there's

64
00:02:47,190 --> 00:02:50,160
also aprof and GUIProfiler
which is slightly less popular.

65
00:02:50,160 --> 00:02:54,540
These all do exactly this
summary analysis visualization.

66
00:02:54,540 --> 00:02:59,790
And actually because there's
a wider profiling ecosystem

67
00:02:59,790 --> 00:03:02,340
beyond R, lots of these
packages can actually

68
00:03:02,340 --> 00:03:06,150
produce conversions
to popular formats

69
00:03:06,150 --> 00:03:07,660
that are using external tools.

70
00:03:07,660 --> 00:03:10,740
So for example, the ability
to convert Rprof formats

71
00:03:10,740 --> 00:03:16,890
to KCachegrind or Google's pprof
tool, or the speed scope format

72
00:03:16,890 --> 00:03:19,770
or also the original flame
graph software format.

73
00:03:19,770 --> 00:03:22,150
These are all available
in the R ecosystem.

74
00:03:22,150 --> 00:03:24,930
So there's a big
existing set of tools

75
00:03:24,930 --> 00:03:27,840
you can use for performance
analysis using the Rprof

76
00:03:27,840 --> 00:03:28,590
function.

77
00:03:28,590 --> 00:03:31,500
Now all of this sounds
great, but let's get

78
00:03:31,500 --> 00:03:34,562
back to that whole Shiny
performance issue for a moment.

79
00:03:34,562 --> 00:03:36,270
One of the interesting
things about Shiny

80
00:03:36,270 --> 00:03:40,240
is that it's often used
by coworkers or peers,

81
00:03:40,240 --> 00:03:42,902
or otherwise as an
internal tool, which

82
00:03:42,902 --> 00:03:45,360
means that the users are often
people who essentially would

83
00:03:45,360 --> 00:03:47,760
send you an email or
a message on Slack

84
00:03:47,760 --> 00:03:50,160
if they were issuing
you some kind of report.

85
00:03:50,160 --> 00:03:53,430
And for example, if you received
some sort of performance bug

86
00:03:53,430 --> 00:03:56,580
report, it's basically you're
going to come down to "Hey,

87
00:03:56,580 --> 00:03:57,700
your app is slow."

88
00:03:57,700 --> 00:03:58,770
"Can you make it faster?"

89
00:03:58,770 --> 00:04:00,840
"So that I can do my job."

90
00:04:00,840 --> 00:04:05,183
And of course this is like not
really a helpful or informative

91
00:04:05,183 --> 00:04:06,600
thing for them to
tell you, so you

92
00:04:06,600 --> 00:04:09,600
start asking follow up questions
like, hey, what were you doing?

93
00:04:09,600 --> 00:04:10,890
And they'll tell you,

94
00:04:10,890 --> 00:04:12,990
"I had clicked x and y."

95
00:04:12,990 --> 00:04:15,720
You'll ask them things
like, OK, that's not really

96
00:04:15,720 --> 00:04:18,540
enough information for me
to recreate your issue.

97
00:04:18,540 --> 00:04:21,402
Do you remember what
you set these inputs to?

98
00:04:21,402 --> 00:04:23,610
And sometimes, they can
remember until you perfectly.

99
00:04:23,610 --> 00:04:27,030
But much more often, usually
they either don't remember

100
00:04:27,030 --> 00:04:27,990
or they misremember.

101
00:04:27,990 --> 00:04:30,720
And they tell you what they
did, but really they didn't.

102
00:04:30,720 --> 00:04:32,310
And you spent a long
time running down

103
00:04:32,310 --> 00:04:35,742
this rabbit hole of trying to
recreate their issue locally.

104
00:04:35,742 --> 00:04:37,200
And the fundamental
reason for this

105
00:04:37,200 --> 00:04:39,900
is that when you're
using Rprof, you have

106
00:04:39,900 --> 00:04:42,630
to be doing profiling locally.

107
00:04:42,630 --> 00:04:47,460
So you're trying to reproduce
an issue or an environment,

108
00:04:47,460 --> 00:04:50,670
and then profiling
locally to collect data

109
00:04:50,670 --> 00:04:53,410
that you can use to
analyze your program.

110
00:04:53,410 --> 00:04:55,200
Now, there's all
kinds of reasons

111
00:04:55,200 --> 00:04:56,310
why this is frustrating.

112
00:04:56,310 --> 00:04:58,050
But in addition to
the frustration,

113
00:04:58,050 --> 00:05:01,350
there's also the problem that
like your local environment

114
00:05:01,350 --> 00:05:05,400
may kind of differ from wherever
your code ends up really

115
00:05:05,400 --> 00:05:07,120
running for these users.

116
00:05:07,120 --> 00:05:10,930
So a classic example of
this is say for myself,

117
00:05:10,930 --> 00:05:14,370
I often write and develop
applications in Canada.

118
00:05:14,370 --> 00:05:15,930
But deploy them to
servers that are

119
00:05:15,930 --> 00:05:18,450
in Europe for European users.

120
00:05:18,450 --> 00:05:21,390
This means that the kind
of databases that they're

121
00:05:21,390 --> 00:05:25,200
connecting to or the other
network services that they

122
00:05:25,200 --> 00:05:28,890
might contact might have very,
very different latency profiles

123
00:05:28,890 --> 00:05:31,770
when they're actually
deployed as opposed to when

124
00:05:31,770 --> 00:05:33,340
I'm working on them locally.

125
00:05:33,340 --> 00:05:37,050
And this can kind of create both
bugs, but also high performance

126
00:05:37,050 --> 00:05:39,360
issues where stuff that
works fast for you locally,

127
00:05:39,360 --> 00:05:42,290
it doesn't work very fast
at all for your users.

128
00:05:42,290 --> 00:05:44,040
So in addition to the
difficulty of trying

129
00:05:44,040 --> 00:05:46,290
to recreate what
your user was doing,

130
00:05:46,290 --> 00:05:48,420
you're also trying to
recreate this environment.

131
00:05:48,420 --> 00:05:51,270
And overall, this is a
fairly error prone process,

132
00:05:51,270 --> 00:05:53,760
and it really slows
down tracking down

133
00:05:53,760 --> 00:05:55,660
performance issues.

134
00:05:55,660 --> 00:05:59,280
So this kind of disconnect
between where code is really

135
00:05:59,280 --> 00:06:01,350
running and where you
want to profile it,

136
00:06:01,350 --> 00:06:04,440
is actually the fundamental
motivation behind a new project

137
00:06:04,440 --> 00:06:07,650
that I've been working
on called xrprof.

138
00:06:07,650 --> 00:06:12,060
Now xrprof is not a clever name,
it just means external Rprof.

139
00:06:12,060 --> 00:06:13,840
And it is exactly that.

140
00:06:13,840 --> 00:06:16,935
It's a stand alone program
that allows you to profile

141
00:06:16,935 --> 00:06:19,380
R code that is already running.

142
00:06:19,380 --> 00:06:21,330
So the fundamental way
of thinking about this

143
00:06:21,330 --> 00:06:25,440
is that Rprof allows
you to profile

144
00:06:25,440 --> 00:06:28,800
by modifying your R
code usually locally

145
00:06:28,800 --> 00:06:30,570
in an interactive session.

146
00:06:30,570 --> 00:06:33,090
xrprof, on the other hand,
is designed and oriented

147
00:06:33,090 --> 00:06:35,730
around profiling R
code that is already

148
00:06:35,730 --> 00:06:38,320
running without modification.

149
00:06:38,320 --> 00:06:40,290
And this is very
powerful if for example,

150
00:06:40,290 --> 00:06:42,990
you want to profile code
that's running in a production

151
00:06:42,990 --> 00:06:46,560
environment, say on Shiny
server, on RStudio Connect,

152
00:06:46,560 --> 00:06:48,870
for R applications that
are running under Docker.

153
00:06:48,870 --> 00:06:52,200
xrprof can see and understand
R programs that are running

154
00:06:52,200 --> 00:06:54,990
and all of those conditions,
and profile them for you

155
00:06:54,990 --> 00:06:56,650
without modifying them.

156
00:06:56,650 --> 00:06:58,770
This allows you to
actually do your profiling

157
00:06:58,770 --> 00:07:00,765
with real users and real data.

158
00:07:00,765 --> 00:07:03,720
It makes it much easier to
track down performance issues,

159
00:07:03,720 --> 00:07:07,320
because you have data
that's close to the source.

160
00:07:07,320 --> 00:07:11,280
Now xrprof is
fundamentally designed

161
00:07:11,280 --> 00:07:15,090
to be a compatible drop in
replacement for Rprof, which

162
00:07:15,090 --> 00:07:17,490
means it produces
the same format.

163
00:07:17,490 --> 00:07:21,720
And it works with all of the
existing R ecosystem tools.

164
00:07:21,720 --> 00:07:23,760
And by extension
through conversions

165
00:07:23,760 --> 00:07:28,170
to other formats, all of the
wider profile world outside

166
00:07:28,170 --> 00:07:30,000
of R.

167
00:07:30,000 --> 00:07:32,340
Because of this compatibility,
it's really, really easy

168
00:07:32,340 --> 00:07:33,240
to use.

169
00:07:33,240 --> 00:07:35,430
And it should be very
familiar if you've used

170
00:07:35,430 --> 00:07:37,050
profiling data in R before.

171
00:07:37,050 --> 00:07:38,880
Now there's another
piece of this puzzle.

172
00:07:38,880 --> 00:07:41,280
One of the other major things
that's happening in the R

173
00:07:41,280 --> 00:07:45,120
ecosystem is that more and more
R packages are making use of C

174
00:07:45,120 --> 00:07:46,740
and C++ code.

175
00:07:46,740 --> 00:07:49,703
Now it's always been possible
to embed native code in R.

176
00:07:49,703 --> 00:07:51,120
It's actually one
of the strengths

177
00:07:51,120 --> 00:07:53,250
of R as a programming language.

178
00:07:53,250 --> 00:07:58,170
But I think partly because of
democratizing tools like Rcpp,

179
00:07:58,170 --> 00:08:02,250
which have made it much easier
for R users to write C++ code.

180
00:08:02,250 --> 00:08:07,150
It's now much more common to
include C++ in an R package.

181
00:08:07,150 --> 00:08:10,500
This is great on the one
hand for performance.

182
00:08:10,500 --> 00:08:12,930
But it does create
a problem, which

183
00:08:12,930 --> 00:08:17,250
is that Rprof can actually
only see functions that are

184
00:08:17,250 --> 00:08:19,500
happening inside of the R code.

185
00:08:19,500 --> 00:08:21,810
So we can only
see our functions.

186
00:08:21,810 --> 00:08:24,600
That means that the more and
more of this code that is

187
00:08:24,600 --> 00:08:29,850
happening in C and C++, the more
is totally invisible to Rprof.

188
00:08:29,850 --> 00:08:33,960
And this creates serious issues
when the C and C++ code is

189
00:08:33,960 --> 00:08:36,659
actually the source of
the performance problem.

190
00:08:36,659 --> 00:08:38,640
Now, I know you
might be thinking.

191
00:08:38,640 --> 00:08:39,330
Hold on.

192
00:08:39,330 --> 00:08:43,530
C in C++ are much faster
than R, and this is true.

193
00:08:43,530 --> 00:08:47,640
But in practice, C and C++
code can make exactly the kind

194
00:08:47,640 --> 00:08:49,920
of poor performance
decision you can make an R.

195
00:08:49,920 --> 00:08:52,260
You can do stuff you
don't really need to do.

196
00:08:52,260 --> 00:08:54,330
You can do things much
more often than you really

197
00:08:54,330 --> 00:08:55,320
need to do them.

198
00:08:55,320 --> 00:08:59,640
Or you can choose kind of
inefficient data structure

199
00:08:59,640 --> 00:09:01,380
to represent the
problem or an algorithm

200
00:09:01,380 --> 00:09:05,110
to actually solve the problem.

201
00:09:05,110 --> 00:09:07,980
So just because code is
written in C and C++,

202
00:09:07,980 --> 00:09:13,180
it doesn't mean that it somehow
becomes free of these issues.

203
00:09:13,180 --> 00:09:17,820
And I think that if you were
trying to track down a C or C++

204
00:09:17,820 --> 00:09:21,060
related performance
issue in an R package,

205
00:09:21,060 --> 00:09:23,670
it's actually been
kind of painful so far.

206
00:09:23,670 --> 00:09:26,490
Either you just guess what
the problem is, and keep

207
00:09:26,490 --> 00:09:27,960
trying various approaches.

208
00:09:27,960 --> 00:09:33,420
Or you try and use some sort of
C or C++ level profiling tool

209
00:09:33,420 --> 00:09:36,300
and an R level profiling
tool at the same time,

210
00:09:36,300 --> 00:09:39,030
and then try and cross-reference
what's happening.

211
00:09:39,030 --> 00:09:42,810
This is actually in practice
a very inexact and frustrating

212
00:09:42,810 --> 00:09:43,390
process.

213
00:09:43,390 --> 00:09:45,030
There's just not
enough information

214
00:09:45,030 --> 00:09:46,770
on either side for
you to be able to knit

215
00:09:46,770 --> 00:09:48,930
these things together.

216
00:09:48,930 --> 00:09:53,760
And this secondary frustration
was actually a big technology

217
00:09:53,760 --> 00:09:55,840
motivation of xrprof as well.

218
00:09:55,840 --> 00:10:00,300
So xrprof can actually see what
is happening in your C and C++

219
00:10:00,300 --> 00:10:00,930
code.

220
00:10:00,930 --> 00:10:05,560
And what it can do is append
that to your R level functions,

221
00:10:05,560 --> 00:10:08,850
so you can see a more holistic
picture of what's going on.

222
00:10:08,850 --> 00:10:11,550
I think this is a really,
really powerful tool, especially

223
00:10:11,550 --> 00:10:13,530
for R package
developers who need

224
00:10:13,530 --> 00:10:16,770
to do performance analysis
that like crosses this language

225
00:10:16,770 --> 00:10:17,580
barrier.

226
00:10:17,580 --> 00:10:20,520
And don't forget that R itself
is actually written in C. So

227
00:10:20,520 --> 00:10:23,130
in practice, sometimes when
you're having performance

228
00:10:23,130 --> 00:10:28,920
issues the touch base R code,
actually the issue is in the C.

229
00:10:28,920 --> 00:10:32,640
So again, what does
this kind of look like?

230
00:10:32,640 --> 00:10:35,160
This is a more involved example.

231
00:10:35,160 --> 00:10:37,170
And in fact, it was
a very real issue

232
00:10:37,170 --> 00:10:39,850
that I first encountered
a couple of years ago.

233
00:10:39,850 --> 00:10:43,770
So at work, we have a whole
bunch of semi-structured data

234
00:10:43,770 --> 00:10:47,520
in a database called MongoDB.

235
00:10:47,520 --> 00:10:49,800
And there's an
existing R package

236
00:10:49,800 --> 00:10:53,100
called mongolite, which can
be used to query MongoDB.

237
00:10:53,100 --> 00:10:55,060
And it actually works
really, really well

238
00:10:55,060 --> 00:10:57,480
the vast majority of the time.

239
00:10:57,480 --> 00:10:59,790
Now if you're not
familiar with MongoDB,

240
00:10:59,790 --> 00:11:03,480
effectively what it
does is store data

241
00:11:03,480 --> 00:11:07,920
as a kind of JSON, which means
that tabular data, the kind you

242
00:11:07,920 --> 00:11:11,370
would see in a CSV
or in a SQL table

243
00:11:11,370 --> 00:11:16,770
is essentially represented as a
JavaScript array of JavaScript

244
00:11:16,770 --> 00:11:17,800
objects.

245
00:11:17,800 --> 00:11:21,480
So this effectively looks like
a big long list of dictionaries

246
00:11:21,480 --> 00:11:26,400
of key value pairs where
every key value or every row

247
00:11:26,400 --> 00:11:29,730
is represented as a dictionary.

248
00:11:29,730 --> 00:11:32,630
Now, it turns out that
there's a known performance

249
00:11:32,630 --> 00:11:37,790
issue with mongolite for a large
databases with lots of columns.

250
00:11:37,790 --> 00:11:40,820
The queries can take a long
time, a surprisingly long time

251
00:11:40,820 --> 00:11:41,817
at least.

252
00:11:41,817 --> 00:11:44,150
And when I first encountered
this a couple of years ago,

253
00:11:44,150 --> 00:11:50,150
I wanted to figure out why,
so I profiled it using Rprof.

254
00:11:50,150 --> 00:11:55,260
But I actually discovered that
I couldn't really see anything.

255
00:11:55,260 --> 00:11:59,330
And the reason for this is that
all of the interesting parts

256
00:11:59,330 --> 00:12:02,120
of mongolite are
actually implemented

257
00:12:02,120 --> 00:12:05,810
in C, which means that it
was very hard to figure out

258
00:12:05,810 --> 00:12:08,010
what was going on.

259
00:12:08,010 --> 00:12:10,430
And so at the time, I did
exactly this very awkward dance

260
00:12:10,430 --> 00:12:13,550
of using C and C++ related
tools and R related tools,

261
00:12:13,550 --> 00:12:15,500
and trying to
cross-reference them.

262
00:12:15,500 --> 00:12:17,970
And it was very painful,
and took me a long time.

263
00:12:17,970 --> 00:12:20,690
And I wasn't even
really ever sure

264
00:12:20,690 --> 00:12:24,020
if that was measuring
the right thing.

265
00:12:24,020 --> 00:12:26,270
So when I redid the
analysis for this talk,

266
00:12:26,270 --> 00:12:29,090
it was kind of comforting
that what had taken me

267
00:12:29,090 --> 00:12:31,520
several days a few
years ago took me

268
00:12:31,520 --> 00:12:35,900
something like 90 seconds
when I used xrprof.

269
00:12:35,900 --> 00:12:38,690
And so what would I see?

270
00:12:38,690 --> 00:12:43,430
And so this is what
happens when you use Rprof.

271
00:12:43,430 --> 00:12:47,090
This is a FlameGraph
of what you would see,

272
00:12:47,090 --> 00:12:48,685
which is not that informative.

273
00:12:48,685 --> 00:12:50,060
Because you just
don't see what's

274
00:12:50,060 --> 00:12:53,930
happening inside of the R code
that's mostly implemented in C.

275
00:12:53,930 --> 00:12:57,320
But if you can see the C code,
this is what you will see.

276
00:12:57,320 --> 00:12:59,810
So here are the R
functions are in blue,

277
00:12:59,810 --> 00:13:01,757
and the C functions
are an orange.

278
00:13:01,757 --> 00:13:03,590
Now of course, I know
this is much too small

279
00:13:03,590 --> 00:13:05,715
for you to actually be able
to read function names,

280
00:13:05,715 --> 00:13:08,040
and that's not really the point.

281
00:13:08,040 --> 00:13:09,920
So I'll just point
out a couple of things

282
00:13:09,920 --> 00:13:15,090
that I was able to pick up
on once I had this view.

283
00:13:15,090 --> 00:13:17,780
The first is that there's
a certain amount of time

284
00:13:17,780 --> 00:13:22,160
that R is communicating
with Mongo itself.

285
00:13:22,160 --> 00:13:25,310
And this is important,
because effectively, this

286
00:13:25,310 --> 00:13:28,070
represents the total upper
bounds of how fast we could

287
00:13:28,070 --> 00:13:29,900
ever possibly make this R code.

288
00:13:29,900 --> 00:13:33,380
Because the reality is we still
need to spend time transmitting

289
00:13:33,380 --> 00:13:35,275
data from the database
over the network,

290
00:13:35,275 --> 00:13:37,400
and there's nothing really
we can do about the time

291
00:13:37,400 --> 00:13:42,030
that it takes to do that other
than say querying less data.

292
00:13:42,030 --> 00:13:45,290
So this kind of serves
as a total upper bound.

293
00:13:45,290 --> 00:13:47,720
But there were two
kind of odd things

294
00:13:47,720 --> 00:13:50,840
that I noticed when
R picked up on,

295
00:13:50,840 --> 00:13:52,850
when I looked at
these profiles, which

296
00:13:52,850 --> 00:13:58,917
is that R spending a lot
of time allocating memory.

297
00:13:58,917 --> 00:14:00,500
And if you don't
know what that means,

298
00:14:00,500 --> 00:14:02,780
well mostly it doesn't matter.

299
00:14:02,780 --> 00:14:06,290
Because allocating memory
is normally really fast.

300
00:14:06,290 --> 00:14:09,560
And in order for allocating
memory to show up on a profile,

301
00:14:09,560 --> 00:14:11,390
it means it needs to
be happening a lot,

302
00:14:11,390 --> 00:14:13,610
or at least happening
really inefficiently.

303
00:14:13,610 --> 00:14:17,432
So when I saw this, it
immediately piqued my interest.

304
00:14:17,432 --> 00:14:18,890
And it made me
think, what could be

305
00:14:18,890 --> 00:14:22,813
causing this many allocations.

306
00:14:22,813 --> 00:14:24,230
The second thing
that I noticed is

307
00:14:24,230 --> 00:14:27,080
that mongolite
seems to be sending

308
00:14:27,080 --> 00:14:30,230
a ton of time transposing
lists, and checking

309
00:14:30,230 --> 00:14:36,020
for uniqueness, which seems like
an odd operation to be doing.

310
00:14:36,020 --> 00:14:37,520
Because again,
checking uniqueness

311
00:14:37,520 --> 00:14:40,590
is normally pretty fast in order
to spend so much time doing it,

312
00:14:40,590 --> 00:14:43,760
you have to be doing it a lot.

313
00:14:43,760 --> 00:14:46,970
So originally actually I
puzzled over this for a while

314
00:14:46,970 --> 00:14:50,510
before I realized that
ultimately, it actually totally

315
00:14:50,510 --> 00:14:51,950
made sense.

316
00:14:51,950 --> 00:14:55,790
So remember how I said that
JSON data represents tabular

317
00:14:55,790 --> 00:14:58,808
data as an array of objects.

318
00:14:58,808 --> 00:15:01,100
Well it turns out that how
mongolite works is that when

319
00:15:01,100 --> 00:15:04,580
it reads in rows, it takes
these JavaScript or these JSON

320
00:15:04,580 --> 00:15:05,870
objects.

321
00:15:05,870 --> 00:15:07,820
And turns them
into R lists, which

322
00:15:07,820 --> 00:15:10,880
is a very natural
representation of a row.

323
00:15:10,880 --> 00:15:16,400
Basically, you have 20
columns, and that gives you

324
00:15:16,400 --> 00:15:17,960
a list of length 20.

325
00:15:17,960 --> 00:15:19,897
And every element
of that list can

326
00:15:19,897 --> 00:15:21,980
have a different type, and
the names of your lists

327
00:15:21,980 --> 00:15:25,400
or the names of your column.

328
00:15:25,400 --> 00:15:27,338
And then what happens
at the end is basically

329
00:15:27,338 --> 00:15:29,630
it takes all of these lists,
and smooshes them together

330
00:15:29,630 --> 00:15:31,760
in a data frame.

331
00:15:31,760 --> 00:15:35,930
Now, this is kind
of interesting,

332
00:15:35,930 --> 00:15:39,950
because if you
imagine, if we were

333
00:15:39,950 --> 00:15:42,320
to create a data
frame in advance,

334
00:15:42,320 --> 00:15:44,570
we knew how many
rows we were getting.

335
00:15:44,570 --> 00:15:47,840
We would essentially
just do one allocation

336
00:15:47,840 --> 00:15:49,470
for every column, right?

337
00:15:49,470 --> 00:15:52,520
So if we have 20 columns,
we do 20 allocations.

338
00:15:52,520 --> 00:15:56,000
But if we read in a
million rows of 20 columns

339
00:15:56,000 --> 00:15:57,920
using this approach,
we do something

340
00:15:57,920 --> 00:16:01,160
like 20 million allocations.

341
00:16:01,160 --> 00:16:03,530
So you can kind of see
where maybe some of this

342
00:16:03,530 --> 00:16:05,630
was showing up in the
profile, because instead

343
00:16:05,630 --> 00:16:08,120
of doing 20 allocations,
we're doing 20 million.

344
00:16:10,850 --> 00:16:14,750
And the second thing is because
we have all these lists,

345
00:16:14,750 --> 00:16:16,640
when we smoosh them
together, we have

346
00:16:16,640 --> 00:16:19,550
to do a bunch of things like
check that all of the names

347
00:16:19,550 --> 00:16:23,548
are the same and all the
types of this are the same.

348
00:16:23,548 --> 00:16:25,340
And we have to do this
for every single row

349
00:16:25,340 --> 00:16:29,210
we add against all the data
that we've previously added.

350
00:16:29,210 --> 00:16:32,720
So again, you can
see how this adds up.

351
00:16:32,720 --> 00:16:36,410
Now, actually this story doesn't
have a super happy ending.

352
00:16:36,410 --> 00:16:38,660
I did propose
changing mongolite,

353
00:16:38,660 --> 00:16:40,317
so that it used a
different algorithm.

354
00:16:40,317 --> 00:16:42,650
The problem was there was a
very complex patch something

355
00:16:42,650 --> 00:16:45,360
like 700 lines of new C
code or something like that.

356
00:16:45,360 --> 00:16:47,660
So it wasn't accepted
into mongolite.

357
00:16:47,660 --> 00:16:49,778
But it was about
five times faster,

358
00:16:49,778 --> 00:16:52,070
which just goes to show that
even though you're writing

359
00:16:52,070 --> 00:16:54,455
something in a fast
language like C or C++,

360
00:16:54,455 --> 00:16:57,260
it doesn't mean you can't
make exactly the same kind

361
00:16:57,260 --> 00:17:01,220
of performance issues that
you encountered in R code.

362
00:17:01,220 --> 00:17:05,240
So hopefully that serves as some
inspiration as to what might

363
00:17:05,240 --> 00:17:08,599
interest you if you're trying
to do remote profiling for any

364
00:17:08,599 --> 00:17:11,750
kind of production code, or
are you trying to do profiling

365
00:17:11,750 --> 00:17:15,909
local or remote that involves
R code that uses lots of C

366
00:17:15,909 --> 00:17:16,409
or C++.

367
00:17:19,400 --> 00:17:23,240
Now, I should say xrprof itself,
the project is open source.

368
00:17:23,240 --> 00:17:25,010
It's available on GitHub.

369
00:17:25,010 --> 00:17:26,420
Most of the
development this year

370
00:17:26,420 --> 00:17:29,570
was generously funded
by the R Consortium.

371
00:17:29,570 --> 00:17:32,930
And I'm currently looking
for users to try it out.

372
00:17:32,930 --> 00:17:33,980
See if it works for you.

373
00:17:33,980 --> 00:17:36,320
See if you can break
it, and let me know.

374
00:17:36,320 --> 00:17:41,360
I'm hoping that xrprof can
become a new tool in the R

375
00:17:41,360 --> 00:17:44,480
profiling tool box.

376
00:17:44,480 --> 00:17:45,740
I'm Aaron Jacobs.

377
00:17:45,740 --> 00:17:49,520
You can find me on Twitter,
on GitHub, and on my own site.

378
00:17:49,520 --> 00:17:51,960
I work at Crescendo
Technology in Toronto.

379
00:17:51,960 --> 00:17:54,080
And if this stuff kind
of piques your interest,

380
00:17:54,080 --> 00:17:55,910
we're always hiring.

381
00:17:55,910 --> 00:17:58,130
Thanks for listening, and
I hope you enjoyed this.

382
00:17:58,130 --> 00:18:02,200
And all of the great talks at
this year's RStudio conference.
