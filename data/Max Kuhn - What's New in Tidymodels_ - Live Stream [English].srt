1
00:00:07,160 --> 00:00:08,210
Hi, I'm Max Kuhn.

2
00:00:08,210 --> 00:00:11,960
I'm a statistician, and work as
a Software Engineer at RStudio.

3
00:00:11,960 --> 00:00:15,710
I mostly focus on open source
tools for building models.

4
00:00:15,710 --> 00:00:17,930
I run the tidymodels
group, and tidymodels

5
00:00:17,930 --> 00:00:19,640
the collection of
R packages that

6
00:00:19,640 --> 00:00:21,140
have very similar
syntax and design

7
00:00:21,140 --> 00:00:23,032
principles in the Tidyverse.

8
00:00:23,032 --> 00:00:24,490
So we've made a
lot of improvements

9
00:00:24,490 --> 00:00:26,300
to Tidymodels in the
less six months.

10
00:00:26,300 --> 00:00:29,700
Some of those improvements have
been around user interfaces,

11
00:00:29,700 --> 00:00:32,500
so we have better ways of
specifying which predictors

12
00:00:32,500 --> 00:00:33,940
are added to our model.

13
00:00:33,940 --> 00:00:35,440
We've made other
improvements around

14
00:00:35,440 --> 00:00:37,060
computational efficiency.

15
00:00:37,060 --> 00:00:40,030
So we have limited support
now for sparse matrices

16
00:00:40,030 --> 00:00:42,820
and expanded support
for parallel processing.

17
00:00:42,820 --> 00:00:45,700
Now I like to talk about more
in this video a specific package

18
00:00:45,700 --> 00:00:47,590
that we just released
called finetune.

19
00:00:47,590 --> 00:00:50,590
And finetune is an expansion
of our tune package,

20
00:00:50,590 --> 00:00:53,890
and gives two additional ways
to optimize hyperparameters

21
00:00:53,890 --> 00:00:55,455
or tuning parameters of models.

22
00:00:55,455 --> 00:00:56,830
Now those are
types of parameters

23
00:00:56,830 --> 00:00:59,037
that can't be directly
estimated from the data,

24
00:00:59,037 --> 00:01:01,120
such as the number of
neighbors in the k-nearest

25
00:01:01,120 --> 00:01:02,360
neighbor model.

26
00:01:02,360 --> 00:01:05,830
And so one variation we'll
look at in this presentation

27
00:01:05,830 --> 00:01:08,230
is a new method of
doing grid search,

28
00:01:08,230 --> 00:01:11,410
and the other method is
another iterative method

29
00:01:11,410 --> 00:01:14,300
called simulated anneal.

30
00:01:14,300 --> 00:01:16,550
To illustrate the methods
that we'll talk about today,

31
00:01:16,550 --> 00:01:20,030
we use a cell segmentation data
from the modeldata package.

32
00:01:20,030 --> 00:01:22,310
It's a two-class
classification problem

33
00:01:22,310 --> 00:01:25,310
with about 58
numeric predictors.

34
00:01:25,310 --> 00:01:27,230
We use a support
vector machine.

35
00:01:27,230 --> 00:01:28,760
And for the support
vector machine,

36
00:01:28,760 --> 00:01:31,280
there's a variety of tuning
parameters, such as the cost

37
00:01:31,280 --> 00:01:33,830
value or the radial
basis function kernel

38
00:01:33,830 --> 00:01:35,300
parameter called sigma.

39
00:01:35,300 --> 00:01:37,730
And then this talk will be
about two different ways

40
00:01:37,730 --> 00:01:40,400
of finding optimal
parameters of these values.

41
00:01:40,400 --> 00:01:44,100
Now these tuning parameter
values are important.

42
00:01:44,100 --> 00:01:47,810
They have a big influence on
the model fit in performance.

43
00:01:47,810 --> 00:01:51,030
The problem is we can't directly
estimate them from the data,

44
00:01:51,030 --> 00:01:53,090
so we need to find
good ways of coming up

45
00:01:53,090 --> 00:01:55,640
with values for
those two parameters,

46
00:01:55,640 --> 00:01:58,070
even though we can't
directly estimate them.

47
00:01:58,070 --> 00:02:01,010
To measure performance, we'll
use 10-fold cross-validation,

48
00:02:01,010 --> 00:02:03,750
and we'll measure the
area under the ROC curve.

49
00:02:03,750 --> 00:02:05,750
Now, the model definitions
and the complete code

50
00:02:05,750 --> 00:02:08,210
set that you can use to
reproduce these analyzes are

51
00:02:08,210 --> 00:02:09,169
shown at the link here.

52
00:02:13,383 --> 00:02:15,050
So to give some
visual demonstration

53
00:02:15,050 --> 00:02:16,580
of what we're
trying to do, what I

54
00:02:16,580 --> 00:02:18,788
did is it took these two
different tuning parameters.

55
00:02:18,788 --> 00:02:21,740
And generate a very large
grid, and resampled them.

56
00:02:21,740 --> 00:02:24,710
And that gives a sense of what
the truly best result would

57
00:02:24,710 --> 00:02:26,340
be from our search.

58
00:02:26,340 --> 00:02:29,180
And you can see here on the left
hand side, this contour plot,

59
00:02:29,180 --> 00:02:32,690
blue values indicate poor
performance of the ROC curve,

60
00:02:32,690 --> 00:02:35,450
and then white values
are more optimal.

61
00:02:35,450 --> 00:02:37,920
And so you can see the lower
diagonal of the search space

62
00:02:37,920 --> 00:02:40,460
is pretty flat
and not very good.

63
00:02:40,460 --> 00:02:41,960
And as you go to
the upper diagonal,

64
00:02:41,960 --> 00:02:44,390
there's sort of like a
little mountainous ridge that

65
00:02:44,390 --> 00:02:45,830
has good performance values.

66
00:02:45,830 --> 00:02:48,500
And the best performance value
on the left hand side plot

67
00:02:48,500 --> 00:02:50,660
as shown by the black dot.

68
00:02:50,660 --> 00:02:53,300
And any, really, point
along the ridge that goes in

69
00:02:53,300 --> 00:02:56,700
that black dot were down
towards the Southeast,

70
00:02:56,700 --> 00:02:58,310
we give a pretty
good performance.

71
00:02:58,310 --> 00:03:00,663
The problem is if we
go over that ridge,

72
00:03:00,663 --> 00:03:03,080
that dark spot there which you
can see a little bit better

73
00:03:03,080 --> 00:03:05,540
on the right hand
side surface plot

74
00:03:05,540 --> 00:03:07,740
gives really, really
poor performance.

75
00:03:07,740 --> 00:03:10,910
So we want to find the values
of these tuning parameters,

76
00:03:10,910 --> 00:03:14,230
and we'll be trying to find the
best ones which are indicated

77
00:03:14,230 --> 00:03:15,500
in the white on the plots.

78
00:03:20,108 --> 00:03:21,650
Now the first method
we'll talk about

79
00:03:21,650 --> 00:03:23,340
is something called
racing methods,

80
00:03:23,340 --> 00:03:25,340
and this is sort of an
alteration of grid search

81
00:03:25,340 --> 00:03:27,440
that's been around
for quite a while.

82
00:03:27,440 --> 00:03:30,140
Now in ordinary grid
search, what you would do

83
00:03:30,140 --> 00:03:32,870
is come up with a candidate
set of parameter values

84
00:03:32,870 --> 00:03:33,990
that you want to try.

85
00:03:33,990 --> 00:03:35,990
And then you'd measure
their performance usually

86
00:03:35,990 --> 00:03:39,140
using resampling, and then pick
the one that seems to be best

87
00:03:39,140 --> 00:03:41,588
or gives you has the
characteristics that you like.

88
00:03:41,588 --> 00:03:43,130
Now the problem with
this is you have

89
00:03:43,130 --> 00:03:46,100
to evaluate a potentially
large number of models

90
00:03:46,100 --> 00:03:49,627
to get performance estimates
until you can make a decision.

91
00:03:49,627 --> 00:03:51,710
So let's say we do 20
values of the support vector

92
00:03:51,710 --> 00:03:54,050
machine tuning
parameters, and then we

93
00:03:54,050 --> 00:03:56,120
use 10-fold
cross-validation, that would

94
00:03:56,120 --> 00:03:57,770
be about 200 total model fits.

95
00:03:57,770 --> 00:03:59,670
And we can't make
a decision on which

96
00:03:59,670 --> 00:04:03,060
tuning parameters are good or
bad until we do all that work.

97
00:04:03,060 --> 00:04:05,390
So what racing methods do
is they sort of incrementally

98
00:04:05,390 --> 00:04:07,290
evaluate the resamples.

99
00:04:07,290 --> 00:04:09,050
So in the first
couple of resamples,

100
00:04:09,050 --> 00:04:11,850
you proceed as normal, and
measure their performance.

101
00:04:11,850 --> 00:04:14,120
And then what you
do subsequently

102
00:04:14,120 --> 00:04:17,180
is do an interim analysis
after each resample

103
00:04:17,180 --> 00:04:18,948
to figure out
basically-- are there

104
00:04:18,948 --> 00:04:20,990
tuning parameters have a
low probability of being

105
00:04:20,990 --> 00:04:22,598
called the best results.

106
00:04:22,598 --> 00:04:24,140
And so one way we
could do that as we

107
00:04:24,140 --> 00:04:26,362
could fit in an ANOVA
model to those results

108
00:04:26,362 --> 00:04:28,820
where the outcome is, let's
say, the area under the ROC

109
00:04:28,820 --> 00:04:32,630
curve, or whatever performance
metric you want to use.

110
00:04:32,630 --> 00:04:36,920
And the predictive
factor is the qualitative

111
00:04:36,920 --> 00:04:39,080
tuning parameter combinations,
like in a model 1,

112
00:04:39,080 --> 00:04:40,830
model 12, and so on.

113
00:04:40,830 --> 00:04:43,100
So what we can do is we
can evaluate those, and see

114
00:04:43,100 --> 00:04:46,400
which ones are statistically
different from the best

115
00:04:46,400 --> 00:04:47,210
possible.

116
00:04:47,210 --> 00:04:49,323
And if they are, we
can discard them.

117
00:04:49,323 --> 00:04:50,990
Now, there's another--
there's a variety

118
00:04:50,990 --> 00:04:52,280
of ways to do racing methods.

119
00:04:52,280 --> 00:04:55,027
We have a second one
implemented in finetune

120
00:04:55,027 --> 00:04:57,110
that uses win-loss statistics
and something called

121
00:04:57,110 --> 00:04:59,390
the Bradley-Terry model,
and treats these data

122
00:04:59,390 --> 00:05:01,398
as if they were
sports competition.

123
00:05:01,398 --> 00:05:03,440
And if you want to learn
more about these methods

124
00:05:03,440 --> 00:05:06,110
and particularly how we
implemented them here,

125
00:05:06,110 --> 00:05:09,758
there's a paper there from
2014 that has the details.

126
00:05:09,758 --> 00:05:11,300
And for our particular
example, we'll

127
00:05:11,300 --> 00:05:16,353
use a grid of 20 support vector
machine candidate values that

128
00:05:16,353 --> 00:05:18,020
are generally with
space-filling design,

129
00:05:18,020 --> 00:05:19,850
and we'll show how
racing can be used

130
00:05:19,850 --> 00:05:22,430
to efficiently evaluate them
compared to ordinary grid

131
00:05:22,430 --> 00:05:24,830
search.

132
00:05:24,830 --> 00:05:26,290
So let's illustrate the race.

133
00:05:26,290 --> 00:05:27,920
So let's say we
take our 10-folds,

134
00:05:27,920 --> 00:05:29,830
and we randomly arrange them.

135
00:05:29,830 --> 00:05:31,390
So they're in a random order.

136
00:05:31,390 --> 00:05:34,570
You take the first fold,
and do what we normally do.

137
00:05:34,570 --> 00:05:38,860
We'd compute our models,
and then make predictions,

138
00:05:38,860 --> 00:05:41,450
and measure let's say the
area under the ROC curve.

139
00:05:41,450 --> 00:05:44,920
Now in the plot which
you see is on the y-axis

140
00:05:44,920 --> 00:05:47,470
is just the model
number, which you just

141
00:05:47,470 --> 00:05:48,670
sort of arbitrarily number.

142
00:05:48,670 --> 00:05:49,675
There's 20 of them.

143
00:05:49,675 --> 00:05:53,930
Now on the x-axis, we see
the measure of performance.

144
00:05:53,930 --> 00:05:56,530
And so the blue
dot from model 12

145
00:05:56,530 --> 00:05:59,110
indicates that it had the
best performance across all

146
00:05:59,110 --> 00:06:00,670
the tuning parameter values.

147
00:06:00,670 --> 00:06:04,330
And then the rest of the points
show the loss of performance

148
00:06:04,330 --> 00:06:05,917
compared to the current best.

149
00:06:05,917 --> 00:06:07,750
So you can see model
12 is the current best,

150
00:06:07,750 --> 00:06:09,940
but model 17 was close behind.

151
00:06:09,940 --> 00:06:11,560
And on the bottom
there, model 16

152
00:06:11,560 --> 00:06:13,580
did not have very
good performance.

153
00:06:13,580 --> 00:06:16,940
And so this is after we've
evaluated the first resample.

154
00:06:16,940 --> 00:06:19,630
Now in the second resample,
we do the same thing.

155
00:06:19,630 --> 00:06:23,170
We just resample and compute
the performance metrics

156
00:06:23,170 --> 00:06:25,390
for all 20 tuning
parameter values.

157
00:06:25,390 --> 00:06:28,120
Now in this plot instead of
the individual ROC values,

158
00:06:28,120 --> 00:06:30,700
these points
represent the average

159
00:06:30,700 --> 00:06:34,930
of two ROC area under the
curve values for each model.

160
00:06:34,930 --> 00:06:38,613
Now perform--the leader switch
from model 12 to model 17,

161
00:06:38,613 --> 00:06:40,030
but you can still
see that there's

162
00:06:40,030 --> 00:06:42,130
a variety of
different models that

163
00:06:42,130 --> 00:06:44,950
do not have very good
performance compared to those.

164
00:06:47,860 --> 00:06:50,435
Now iteration 3, we start
doing the interim analysis.

165
00:06:50,435 --> 00:06:52,060
In this case, we're
going to be talking

166
00:06:52,060 --> 00:06:53,360
about the ANOVA method.

167
00:06:53,360 --> 00:06:55,870
And what that allows us to do
is put a confidence interval

168
00:06:55,870 --> 00:06:57,850
on the loss of
performance compared

169
00:06:57,850 --> 00:07:00,470
to the leader for each
tuning parameter value.

170
00:07:00,470 --> 00:07:02,440
And so you can see the
ones that are in black,

171
00:07:02,440 --> 00:07:04,960
there's no evidence
to reject that they're

172
00:07:04,960 --> 00:07:07,690
statistically different
from the best value in blue.

173
00:07:07,690 --> 00:07:09,250
But the ones in gray
that you can see

174
00:07:09,250 --> 00:07:10,923
are statistically
different from that,

175
00:07:10,923 --> 00:07:13,090
and therefore, we think it
would be pretty good idea

176
00:07:13,090 --> 00:07:15,770
to discard them from
further consideration.

177
00:07:15,770 --> 00:07:17,440
So basically, we use
the ANOVA statistics

178
00:07:17,440 --> 00:07:18,970
to figure out which
tuning parameter

179
00:07:18,970 --> 00:07:22,720
values to keep resampling, and
which ones we can get rid of.

180
00:07:22,720 --> 00:07:24,837
In this particular case
in the third iteration,

181
00:07:24,837 --> 00:07:26,920
we're getting rid of 17
different tuning parameter

182
00:07:26,920 --> 00:07:29,400
values.

183
00:07:29,400 --> 00:07:32,010
Now iteration 4, the
confidence intervals

184
00:07:32,010 --> 00:07:34,680
tighten up, pretty
considerably, and model 1

185
00:07:34,680 --> 00:07:37,530
there falls out to where
we're left with two models.

186
00:07:37,530 --> 00:07:39,120
And as we keep
resampling, you can

187
00:07:39,120 --> 00:07:41,640
see that we're getting
closer and closer

188
00:07:41,640 --> 00:07:43,300
to having one fall out.

189
00:07:43,300 --> 00:07:46,530
And then interation
9 of 10, model 12

190
00:07:46,530 --> 00:07:49,740
finally is discarded, because
it's not statistically--

191
00:07:49,740 --> 00:07:52,560
or because it is statistically
different than the best.

192
00:07:52,560 --> 00:07:56,430
So this is on the 9th fold
out of 10. What we normally

193
00:07:56,430 --> 00:07:59,640
do is if we have any situation
where there's only one left

194
00:07:59,640 --> 00:08:03,240
over, we keep resampling it
til it has the full precision

195
00:08:03,240 --> 00:08:05,890
that we would like to
measure performance.

196
00:08:05,890 --> 00:08:08,820
So after 9 iterations,
basically, we

197
00:08:08,820 --> 00:08:11,550
filter out all but 1
tuning value combination.

198
00:08:11,550 --> 00:08:14,012
And then we just
resample model 17 once.

199
00:08:14,012 --> 00:08:15,720
And what the result
is instead of fitting

200
00:08:15,720 --> 00:08:18,510
the full set of 200
model fits, we actually

201
00:08:18,510 --> 00:08:20,500
considered 74 model fits.

202
00:08:20,500 --> 00:08:23,370
So it's a pretty substantial
reduction in both time

203
00:08:23,370 --> 00:08:25,200
and evaluations of models.

204
00:08:25,200 --> 00:08:28,660
And since our inner analysis
method is not very slow,

205
00:08:28,660 --> 00:08:31,703
we're able to call these
values pretty quickly.

206
00:08:31,703 --> 00:08:33,120
And so the nice
thing about racing

207
00:08:33,120 --> 00:08:36,059
is you can do a very
large grid if you like,

208
00:08:36,059 --> 00:08:37,320
and do it pretty efficiently.

209
00:08:37,320 --> 00:08:38,970
Because chances
are, you will not

210
00:08:38,970 --> 00:08:44,740
be resampling the full grid for
all of the possible resamples.

211
00:08:44,740 --> 00:08:46,960
The code for racing
is shown here.

212
00:08:46,960 --> 00:08:50,118
It's very similar to the tune_grid
function in the tune package.

213
00:08:50,118 --> 00:08:51,910
And you can see that
we first set the seed,

214
00:08:51,910 --> 00:08:54,190
so we make sure we get
reproducible results.

215
00:08:54,190 --> 00:08:57,370
And then what we do is run
the tune_race_anova function,

216
00:08:57,370 --> 00:09:00,040
its arguments are very,
very similar to tune_grid.

217
00:09:00,040 --> 00:09:02,530
The relevant one that's shown
here is the grid argument,

218
00:09:02,530 --> 00:09:05,560
and that could either be an
integer that says, basically

219
00:09:05,560 --> 00:09:07,660
how many tuning parameter
combinations you

220
00:09:07,660 --> 00:09:09,580
want to evaluate,
and let the function

221
00:09:09,580 --> 00:09:10,845
figure out which to do.

222
00:09:10,845 --> 00:09:12,220
Or you could pass
in a data frame

223
00:09:12,220 --> 00:09:14,262
there that has the exact
combinations that you're

224
00:09:14,262 --> 00:09:15,220
interested in.

225
00:09:15,220 --> 00:09:16,720
There's a control
argument that lets

226
00:09:16,720 --> 00:09:19,060
you specify a lot of the
numerical aspects of things

227
00:09:19,060 --> 00:09:21,250
like, the size of the
confidence interval that you

228
00:09:21,250 --> 00:09:23,420
use for elimination and so on.

229
00:09:23,420 --> 00:09:25,390
There's also a
verbose_elim option

230
00:09:25,390 --> 00:09:27,610
that does some logging
that shows you the progress

231
00:09:27,610 --> 00:09:28,765
as you proceed.

232
00:09:28,765 --> 00:09:30,640
You can see there it
shows that we eliminated

233
00:09:30,640 --> 00:09:34,850
17 tuning parameter values in
the first iteration and so on.

234
00:09:34,850 --> 00:09:37,690
Now if you'd like to try the
other racing method that's

235
00:09:37,690 --> 00:09:39,940
based on win-loss
statistics, that function

236
00:09:39,940 --> 00:09:42,130
is called tune_race_win_loss.

237
00:09:42,130 --> 00:09:43,930
And the syntax is
identical to what

238
00:09:43,930 --> 00:09:48,510
we see here in tune_race_anova.

239
00:09:48,510 --> 00:09:52,102
So as I mentioned, racing is
really a grid search method

240
00:09:52,102 --> 00:09:53,310
that's done very efficiently.

241
00:09:53,310 --> 00:09:55,770
And again in grid search,
you predefine all the values

242
00:09:55,770 --> 00:09:57,040
you want to look at.

243
00:09:57,040 --> 00:09:58,500
So the next method
we'll talk about

244
00:09:58,500 --> 00:10:01,320
is an iterative search method
based on simulated annealing

245
00:10:01,320 --> 00:10:05,470
where new values are determined
after each current value.

246
00:10:05,470 --> 00:10:09,110
So you don't predefine
the tuning parameter values.

247
00:10:09,110 --> 00:10:12,700
So simulated annealing is really a
pretty old search routine,

248
00:10:12,700 --> 00:10:14,500
and it conducts a biased
random walk around

249
00:10:14,500 --> 00:10:16,060
our tuning parameter space.

250
00:10:16,060 --> 00:10:19,600
And the bias comes in because
once it creates a new tuning

251
00:10:19,600 --> 00:10:22,660
parameter candidate
and evaluates it,

252
00:10:22,660 --> 00:10:25,150
it may discard that
from the search.

253
00:10:25,150 --> 00:10:26,830
And pretend like
it never existed.

254
00:10:26,830 --> 00:10:32,380
Or if the results are not too
far from optimal or a new best,

255
00:10:32,380 --> 00:10:34,790
it would accept that,
and proceed from there.

256
00:10:34,790 --> 00:10:36,880
So we'll show that in
detail in a little bit

257
00:10:36,880 --> 00:10:39,435
as we show the example.

258
00:10:39,435 --> 00:10:40,810
One thing we should
talk about is

259
00:10:40,810 --> 00:10:44,938
how simulating comes up with
its next value to evaluate.

260
00:10:44,938 --> 00:10:46,480
So on the right hand
side, we sort of

261
00:10:46,480 --> 00:10:49,090
have a plot where the black
line shows a search that's

262
00:10:49,090 --> 00:10:51,850
gone through 6 iterations,
and is slowly going down

263
00:10:51,850 --> 00:10:54,280
towards the bottom right.

264
00:10:54,280 --> 00:10:56,710
And then, once we are
at that last point,

265
00:10:56,710 --> 00:11:00,100
we need to generate values that
are within a local neighborhood

266
00:11:00,100 --> 00:11:01,510
of the current best.

267
00:11:01,510 --> 00:11:03,633
So what simulated annealing
would do is find values

268
00:11:03,633 --> 00:11:05,050
that are not too different
from the one

269
00:11:05,050 --> 00:11:06,830
you're currently evaluating.

270
00:11:06,830 --> 00:11:10,540
So what we've done
is we've generated

271
00:11:10,540 --> 00:11:12,340
a variety of random
combinations, that

272
00:11:12,340 --> 00:11:15,430
are shown in red there, that
are within some sort of radius

273
00:11:15,430 --> 00:11:16,872
around the current best.

274
00:11:16,872 --> 00:11:19,330
And then, we would select one
from random as the next point

275
00:11:19,330 --> 00:11:21,500
that we should evaluate.

276
00:11:21,500 --> 00:11:23,710
Now the biased random
walk part comes in

277
00:11:23,710 --> 00:11:26,320
because, if we select one
of those and the performance

278
00:11:26,320 --> 00:11:29,630
is not as good as the current
value, we have two choices.

279
00:11:29,630 --> 00:11:32,140
The other algorithm can
either accept it, and proceed

280
00:11:32,140 --> 00:11:33,640
from it going forward.

281
00:11:33,640 --> 00:11:37,570
Or discard it, and again pretend
as if it was never generated.

282
00:11:37,570 --> 00:11:41,050
In the determining factors for
whether we discard or accept

283
00:11:41,050 --> 00:11:43,420
a result are based
on two things. One

284
00:11:43,420 --> 00:11:45,730
is how early you are
in the search process.

285
00:11:45,730 --> 00:11:48,560
So you're much more likely
to accept suboptimal values

286
00:11:48,560 --> 00:11:51,350
at the early parts of
the search progress.

287
00:11:51,350 --> 00:11:53,300
That's how simulated
annealing works.

288
00:11:53,300 --> 00:11:55,090
And as you get to
the later iterations,

289
00:11:55,090 --> 00:11:58,780
you're much less likely
to accept poor values.

290
00:11:58,780 --> 00:12:00,880
Now the second factor
in that decision

291
00:12:00,880 --> 00:12:03,530
is how bad was the
current result.

292
00:12:03,530 --> 00:12:05,620
So if the current result
is just slightly worse

293
00:12:05,620 --> 00:12:07,600
than the current
best, it's more likely

294
00:12:07,600 --> 00:12:08,870
that you would accept it.

295
00:12:08,870 --> 00:12:11,110
But if it's a
really awful point,

296
00:12:11,110 --> 00:12:13,000
probabilistically,
it's less likely

297
00:12:13,000 --> 00:12:15,370
that you would consider
that is the current point,

298
00:12:15,370 --> 00:12:17,565
and base your next
point off of that one.

299
00:12:17,565 --> 00:12:18,940
So we'll show this
in some detail

300
00:12:18,940 --> 00:12:19,982
with our current example.

301
00:12:22,440 --> 00:12:24,850
So here's our search space
that we looked at earlier.

302
00:12:24,850 --> 00:12:27,710
I've generated a grid of four
different tuning parameter

303
00:12:27,710 --> 00:12:30,620
values, and evaluated
them using resampling.

304
00:12:30,620 --> 00:12:35,240
The current best from that
grid is the green dot.

305
00:12:35,240 --> 00:12:37,385
Simulated annealing will
start from that green dot,

306
00:12:37,385 --> 00:12:38,757
and proceed from there.

307
00:12:38,757 --> 00:12:40,340
So on the first
iteration, we're going

308
00:12:40,340 --> 00:12:41,810
to define again
this neighborhood

309
00:12:41,810 --> 00:12:45,420
around that green dot, and
randomly generate a point.

310
00:12:45,420 --> 00:12:47,990
And so when we did that, it actually
turns out it's a new best.

311
00:12:47,990 --> 00:12:50,340
It's going towards
the better results.

312
00:12:50,340 --> 00:12:53,900
And so we keep that, and then
base the iteration 2 results

313
00:12:53,900 --> 00:12:55,450
on this value.

314
00:12:55,450 --> 00:12:58,670
Now in iteration 2, we go
in kind of a poor direction,

315
00:12:58,670 --> 00:13:00,860
and get actually
fairly bad results.

316
00:13:00,860 --> 00:13:03,440
And they're low enough to
where we would discard this

317
00:13:03,440 --> 00:13:04,910
as being suboptimal.

318
00:13:04,910 --> 00:13:07,040
And so we go to
iteration 3, it's

319
00:13:07,040 --> 00:13:08,780
based on results
from iteration 1

320
00:13:08,780 --> 00:13:10,650
as you'll see in just a second.

321
00:13:10,650 --> 00:13:12,350
So discarding it
means, we do not

322
00:13:12,350 --> 00:13:16,320
use it to generate the
next point in the search.

323
00:13:16,320 --> 00:13:19,720
So in iteration 3, you see
we get another new best,

324
00:13:19,720 --> 00:13:22,470
and then we can keep
going around the search

325
00:13:22,470 --> 00:13:25,218
by finding things in
our local neighborhood.

326
00:13:25,218 --> 00:13:27,260
Now, one of the things
about simulating annealing

327
00:13:27,260 --> 00:13:28,802
is it's a global
search method, which

328
00:13:28,802 --> 00:13:32,960
means it can go back, and
reevaluate areas that it

329
00:13:32,960 --> 00:13:35,040
might have already evaluated.

330
00:13:35,040 --> 00:13:37,940
And so in this particular
result on interation 8,

331
00:13:37,940 --> 00:13:40,250
it goes back in a
different direction.

332
00:13:40,250 --> 00:13:42,002
And we accepted a suboptimal.

333
00:13:42,002 --> 00:13:44,210
As you can see, we're going
to go into an area that's

334
00:13:44,210 --> 00:13:48,590
not very good, and we're getting
a series of just poor results.

335
00:13:48,590 --> 00:13:50,780
Now simulated annealing
also has this feature

336
00:13:50,780 --> 00:13:52,095
where you can do a restart.

337
00:13:52,095 --> 00:13:54,470
So if you don't have good
results within a certain number

338
00:13:54,470 --> 00:13:56,810
of iterations, you
can trigger the search

339
00:13:56,810 --> 00:13:59,210
to start from its
last known best point

340
00:13:59,210 --> 00:14:00,500
and proceed from there.

341
00:14:00,500 --> 00:14:02,870
And that is actually
what happens here.

342
00:14:02,870 --> 00:14:05,330
But we still have another
suboptimal result,

343
00:14:05,330 --> 00:14:08,900
and then we start to search
again from the current best.

344
00:14:08,900 --> 00:14:11,680
And so we proceed along here.

345
00:14:11,680 --> 00:14:12,670
It happens again.

346
00:14:12,670 --> 00:14:16,970
We go off in a bad direction
and then we restart.

347
00:14:16,970 --> 00:14:19,400
And so you can see, we're close
to a number of iterations,

348
00:14:19,400 --> 00:14:21,280
so I did 30 iterations here.

349
00:14:21,280 --> 00:14:23,680
And it would just
continue to look until it

350
00:14:23,680 --> 00:14:27,430
finds better and better values.

351
00:14:27,430 --> 00:14:29,250
So that's a little
graphical representation

352
00:14:29,250 --> 00:14:30,900
of how simulated
annealing works.

353
00:14:30,900 --> 00:14:32,880
If you want to use
this in code, the code

354
00:14:32,880 --> 00:14:34,350
is very similar
to the tune based

355
00:14:34,350 --> 00:14:36,360
function in the tune package.

356
00:14:36,360 --> 00:14:38,250
The arguments are
almost all the same.

357
00:14:38,250 --> 00:14:41,623
You could tell a number of
iterations to proceed from.

358
00:14:41,623 --> 00:14:43,290
Again, there's another
control parameter

359
00:14:43,290 --> 00:14:47,230
that determines things like
the size of local neighborhood

360
00:14:47,230 --> 00:14:49,800
and so on, so it has some
of the numerical properties

361
00:14:49,800 --> 00:14:52,290
that you can tweak for
simulated annealing.

362
00:14:52,290 --> 00:14:53,740
And it also has a verbose method.

363
00:14:53,740 --> 00:14:56,250
So if you set that to true,
you get some nice logging

364
00:14:56,250 --> 00:14:58,410
as the search continues.

365
00:14:58,410 --> 00:15:01,733
What's nice about this is if
you're running interactively,

366
00:15:01,733 --> 00:15:03,150
and it's been
running for a while,

367
00:15:03,150 --> 00:15:06,420
and you feel like maybe it's
done as best as it could do,

368
00:15:06,420 --> 00:15:08,220
you can manually
interrupt the execution

369
00:15:08,220 --> 00:15:10,380
of the tune_sim_anneal function,

370
00:15:10,380 --> 00:15:11,940
and it will return
all the results

371
00:15:11,940 --> 00:15:13,500
that it's achieved so far.

372
00:15:13,500 --> 00:15:14,938
So by manually
interrupting it, you

373
00:15:14,938 --> 00:15:16,980
don't lose all the results
that you've generated.

374
00:15:16,980 --> 00:15:21,973
It will give you the ones
that you've completed to date.

375
00:15:21,973 --> 00:15:23,640
And so that's the
other function that we

376
00:15:23,640 --> 00:15:27,550
wanted to show for model
tuning in the finetune package.

377
00:15:27,550 --> 00:15:30,682
If you want to learn more, look
at tidymodels.org especially

378
00:15:30,682 --> 00:15:31,890
if you're new to Tidymodels.

379
00:15:31,890 --> 00:15:35,220
It has a lot of articles
on getting started,

380
00:15:35,220 --> 00:15:38,250
a nice sequence of examples
of how to use recipes,

381
00:15:38,250 --> 00:15:40,555
and parsnip, and a variety
of different things.

382
00:15:40,555 --> 00:15:42,180
There's other articles
there for people

383
00:15:42,180 --> 00:15:45,360
who have used it where
in more advanced articles

384
00:15:45,360 --> 00:15:47,970
that show different
aspects of Tidymodels.

385
00:15:47,970 --> 00:15:50,870
Julia Silge and I are also
writing a book on tidymodels.

386
00:15:50,870 --> 00:15:54,630
It's about halfway done
at the end of 2020.

387
00:15:54,630 --> 00:15:56,490
Chapter 13 is about
grid search, and it

388
00:15:56,490 --> 00:15:58,260
has more details about racing.

389
00:15:58,260 --> 00:16:00,183
And Chapter 14 is
about iterative search,

390
00:16:00,183 --> 00:16:01,600
and one of the
things it describes

391
00:16:01,600 --> 00:16:02,980
there is simulated annealing.

392
00:16:02,980 --> 00:16:04,980
You can also look at the
finetune webpage, which

393
00:16:04,980 --> 00:16:08,850
has a nice formatted reference
section, as well as a blog post

394
00:16:08,850 --> 00:16:11,490
that we used to
launch the package.

395
00:16:11,490 --> 00:16:14,630
Thanks for watching,
and I hope you enjoy it.
